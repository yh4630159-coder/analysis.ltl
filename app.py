import streamlit as st
import pandas as pd
import io
import re

# ================= 1. é…ç½®ä¸æ˜ å°„ (V2.7 åŸºç¡€) =================
COLUMN_MAPS = {
    'WP': { # WesternPost ç®€å†™åŒ¹é…æ–‡ä»¶å
        'SKU': 'SKU', 'Warehouse': 'ä»“åº“/Warehouse', 
        'Qty': 'æ•°é‡/Quantity', 'Fee': 'é‡‘é¢/Amount', 
        'Age': 'åº“é¾„/Library of Age', 'Vol': 'ä½“ç§¯(mÂ³)',
        'Full_Name': 'WesternPost'
    },
    'LG': { # ä¹ä»“
        'SKU': 'ä¹ä»“è´§å“ç¼–ç ', 'Warehouse': 'ä»“åº“', 
        'Qty': 'æ•°é‡', 'Fee': 'è®¡ç®—é‡‘é¢', 
        'Age': 'åº“é¾„', 'Vol': 'æ€»ä½“ç§¯',
        'Full_Name': 'Lecangs'
    },
    'AI': { # AIä»“
        'SKU': 'SKU', 'Warehouse': 'ä»“åº“', 
        'Qty': 'åº“å­˜', 'Fee': 'è´¹ç”¨', 
        'Age': 'åœ¨åº“å¤©æ•°', 'Vol': 'ç«‹æ–¹æ•°',
        'Full_Name': 'AI'
    },
    'WL': { # ä¸‡é‚‘é€š
        'SKU': 'å•†å“SKU', 'Warehouse': 'å®é™…å‘è´§ä»“åº“', 
        'Qty': 'åº“å­˜æ€»æ•°_QTY', 'Fee': 'è®¡è´¹æ€»ä»·', 
        'Age': 'åº“å­˜åº“é¾„_CD', 'Vol': 'è®¡è´¹æ€»ä½“ç§¯_ç«‹æ–¹ç±³',
        'Full_Name': 'WWL'
    }
}

AGE_BINS = [0, 30, 60, 90, 120, 180, 360, 99999]
AGE_LABELS = ['0-30å¤©', '31-60å¤©', '61-90å¤©', '91-120å¤©', '120-180å¤©', '180-360å¤©', '360å¤©+']

# ================= 2. æ ¸å¿ƒå¤„ç†é€»è¾‘ =================

def parse_filename(filename):
    """
    è§£ææ–‡ä»¶åï¼Œæå–ï¼šéƒ¨é—¨ã€æœåŠ¡å•†ã€æ—¥æœŸ
    æœŸæœ›æ ¼å¼ï¼šéƒ¨é—¨_æœåŠ¡å•†_YYYY-MM.xlsx (ä¾‹å¦‚ï¼šä¸šåŠ¡ä¸€éƒ¨_AI_2024-01.xlsx)
    """
    # å»æ‰åç¼€
    name_body = filename.rsplit('.', 1)[0]
    parts = name_body.split('_')
    
    if len(parts) >= 3:
        dept = parts[0]
        provider_code = parts[1].upper() # è½¬å¤§å†™ä»¥åŒ¹é… key
        date_str = parts[2]
        return dept, provider_code, date_str
    return None, None, None

def find_header_row(df, mapping, max_scan=10):
    best_score = 0
    best_header_row = 0
    expected_cols = set(mapping.values())
    expected_cols.discard(mapping.get('Full_Name')) # å»æ‰éåˆ—åçš„key
    
    for i in range(min(len(df), max_scan)):
        row_values = df.iloc[i].astype(str).str.strip().tolist()
        score = sum(1 for col in row_values if col in expected_cols)
        if score > best_score:
            best_score = score
            best_header_row = i
    if best_score < 2: return 0
    return best_header_row + 1

def load_data_v3(file):
    # 1. è§£ææ–‡ä»¶å
    dept, provider_code, date_str = parse_filename(file.name)
    
    # å¦‚æœæ–‡ä»¶åä¸ç¬¦åˆè§„åˆ™ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é… (ä¸ºäº†å…¼å®¹æ—§ä¹ æƒ¯ï¼Œé»˜è®¤ä¸ºæœªçŸ¥éƒ¨é—¨)
    if not dept:
        dept = "é»˜è®¤éƒ¨é—¨"
        # å°è¯•ä»æ–‡ä»¶åçŒœæœåŠ¡å•†
        for code in COLUMN_MAPS.keys():
            if code in file.name.upper():
                provider_code = code
                break
        date_str = "æœ€æ–°" # æ— æ³•è§£ææ—¥æœŸ

    if provider_code not in COLUMN_MAPS:
        st.toast(f"âš ï¸ è·³è¿‡æ–‡ä»¶ {file.name}: æ— æ³•è¯†åˆ«æœåŠ¡å•†(AI/WL/LG/WP)", icon="â­ï¸")
        return pd.DataFrame()

    # 2. è¯»å–å†…å®¹ (V2.7 çš„å¼ºåŠ›è¯»å–é€»è¾‘)
    df = None
    try: df = pd.read_excel(file, engine='openpyxl', header=None) 
    except: pass
    if df is None:
        try: file.seek(0); df = pd.read_csv(file, encoding='utf-8', header=None)
        except: pass
    if df is None:
        try: file.seek(0); df = pd.read_csv(file, encoding='gb18030', header=None)
        except: pass
            
    if df is None:
        return pd.DataFrame()

    try:
        mapping = COLUMN_MAPS[provider_code]
        
        # æ™ºèƒ½è¡¨å¤´
        header_idx = 0
        expected_cols = set(mapping.values())
        expected_cols.discard(mapping.get('Full_Name'))
        
        for i in range(min(20, len(df))):
            row_values = df.iloc[i].astype(str).str.strip().tolist()
            row_values = [x.replace('\ufeff', '') for x in row_values]
            if sum(1 for x in row_values if x in expected_cols) >= 2:
                header_idx = i
                break
        
        new_columns = df.iloc[header_idx].astype(str).str.strip().str.replace('\ufeff', '')
        df = df.iloc[header_idx+1:].copy()
        df.columns = new_columns

        # æ ‡å‡†æ¸…æ´—
        valid_map = {k: v for k, v in mapping.items() if v in df.columns}
        rename_dict = {v: k for k, v in valid_map.items()}
        df = df.rename(columns=rename_dict)
        
        for col in ['Qty', 'Fee', 'Age', 'Vol']:
            if col not in df.columns: df[col] = 0
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
        # åº“é¾„å¤„ç†
        cut_series = pd.cut(df['Age'], bins=AGE_BINS, labels=AGE_LABELS, right=False)
        df['Age_Range'] = cut_series.astype(str)
        df.loc[df['Age_Range'] == 'nan', 'Age_Range'] = '360å¤©+'
        df['Age_Range'] = df['Age_Range'].str.strip()

        # ğŸŒŸ V3.0 æ–°å¢ç»´åº¦
        df['Dept'] = dept
        df['Provider'] = mapping['Full_Name']
        df['Date'] = date_str
        
        return df
        
    except Exception as e:
        return pd.DataFrame()

# ================= 3. ç•Œé¢é€»è¾‘ =================
st.set_page_config(page_title="æµ·å¤–ä»“åº“å­˜ BI V3.0", page_icon="ğŸ“ˆ", layout="wide")
st.title("ğŸ“ˆ æµ·å¤–ä»“å¤šéƒ¨é—¨è¶‹åŠ¿åˆ†æçœ‹æ¿ (V3.0)")

with st.expander("â„¹ï¸ ä½¿ç”¨æŒ‡å— & å‘½åè§„èŒƒ (å¿…è¯»)", expanded=False):
    st.markdown("""
    **è¦æƒ³å®ç°è¶‹åŠ¿å¯¹æ¯”ï¼Œè¯·åŠ¡å¿…æŒ‰ä»¥ä¸‹æ ¼å¼é‡å‘½åæ–‡ä»¶ï¼š**
    
    `éƒ¨é—¨åç§°_æœåŠ¡å•†ä»£ç _æ—¥æœŸ.xlsx`
    
    * **éƒ¨é—¨åç§°**ï¼šä¾‹å¦‚ ä¸šåŠ¡ä¸€éƒ¨ã€ä¸šåŠ¡äºŒéƒ¨ã€Amazonå›¢é˜Ÿ
    * **æœåŠ¡å•†ä»£ç **ï¼šå¿…é¡»åŒ…å« **AI, WL, LG, WP** å…¶ä¸­ä¹‹ä¸€
    * **æ—¥æœŸ**ï¼šä¾‹å¦‚ 2024-01, 2024-02
    
    **âœ… æ­£ç¡®ç¤ºä¾‹ï¼š** `ä¸šåŠ¡ä¸€éƒ¨_AI_2024-01.xlsx`
    """)

# --- ä¾§è¾¹æ ï¼šæ‰¹é‡ä¸Šä¼  ---
with st.sidebar:
    st.header("ğŸ“‚ æ•°æ®ä¸­å¿ƒ")
    uploaded_files = st.file_uploader(
        "æ‰¹é‡ä¸Šä¼ æ‰€æœ‰æ–‡ä»¶ (æ”¯æŒå¤šé€‰)", 
        type=['xlsx', 'xls', 'csv'], 
        accept_multiple_files=True
    )
    
    dfs = []
    if uploaded_files:
        progress_bar = st.progress(0)
        for i, file in enumerate(uploaded_files):
            df = load_data_v3(file)
            if not df.empty:
                dfs.append(df)
            progress_bar.progress((i + 1) / len(uploaded_files))
        st.success(f"æˆåŠŸè¯»å– {len(dfs)} ä¸ªæ–‡ä»¶")

if not dfs:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ å¸¦æœ‰ã€éƒ¨é—¨_æœåŠ¡å•†_æ—¥æœŸã€‘å‘½åçš„æ–‡ä»¶ï¼Œå³å¯å¼€å¯è¶‹åŠ¿åˆ†æã€‚")
else:
    full_df = pd.concat(dfs, ignore_index=True)
    
    # é€‰é¡¹å¡åˆ‡æ¢
    tab1, tab2 = st.tabs(["ğŸ“Š å•æœˆ/å•éƒ¨é—¨è¯¦æƒ… (V2.7è§†å›¾)", "ğŸ“ˆ å†å²è¶‹åŠ¿å¯¹æ¯” (V3.0è§†å›¾)"])
    
    # ================= TAB 1: è¯¦æƒ…åˆ†æ =================
    with tab1:
        c1, c2, c3 = st.columns(3)
        with c1:
            # çº§è”é€‰æ‹©
            sel_dept = st.selectbox("é€‰æ‹©éƒ¨é—¨", full_df['Dept'].unique(), key='t1_dept')
        with c2:
            # æ ¹æ®éƒ¨é—¨ç­›é€‰æ—¥æœŸ
            dept_df = full_df[full_df['Dept'] == sel_dept]
            sel_date = st.selectbox("é€‰æ‹©æœˆä»½", sorted(dept_df['Date'].unique(), reverse=True), key='t1_date')
        with c3:
            # æ ¹æ®éƒ¨é—¨å’Œæ—¥æœŸç­›é€‰æœåŠ¡å•†
            date_df = dept_df[dept_df['Date'] == sel_date]
            sel_prov = st.selectbox("é€‰æ‹©æœåŠ¡å•†", date_df['Provider'].unique(), key='t1_prov')
            
        # æœ€ç»ˆç­›é€‰
        target_df = date_df[date_df['Provider'] == sel_prov]
        
        # ä»“åº“é€‰æ‹©
        wh_list = sorted(target_df['Warehouse'].astype(str).unique().tolist())
        wh_list.insert(0, "å…¨éƒ¨ (All Warehouses)")
        sel_wh = st.selectbox("é€‰æ‹©ä»“åº“", wh_list, key='t1_wh')
        
        if sel_wh != "å…¨éƒ¨ (All Warehouses)":
            final_df = target_df[target_df['Warehouse'] == sel_wh]
            wh_name = sel_wh
        else:
            final_df = target_df
            wh_name = "å…¨ä»“æ±‡æ€»"
            
        # --- æ¸²æŸ“ V2.7 çš„å›¾è¡¨ ---
        # (æ­¤å¤„å¤ç”¨ä¹‹å‰çš„ç»Ÿè®¡é€»è¾‘ï¼Œç²¾ç®€å±•ç¤º)
        total_fee = final_df['Fee'].sum()
        total_vol = final_df['Vol'].sum()
        
        k1, k2 = st.columns(2)
        k1.metric("å½“æœˆæ€»è´¹ç”¨", f"${total_fee:,.2f}")
        k2.metric("å½“æœˆæ€»ä½“ç§¯", f"{total_vol:,.2f} mÂ³")
        
        # åº“é¾„è¡¨
        summary = final_df.groupby('Age_Range').agg({'Fee': 'sum', 'Qty': 'sum', 'Vol': 'sum'}).reset_index()
        order_map = {label: i for i, label in enumerate(AGE_LABELS + ['360å¤©+'])}
        summary['sort'] = summary['Age_Range'].map(order_map).fillna(999)
        summary = summary.sort_values('sort').drop('sort', axis=1)
        
        summary['è´¹ç”¨å æ¯”'] = (summary['Fee'] / total_fee * 100).fillna(0)
        
        st.dataframe(
            summary.style.format({'Fee': '${:.2f}', 'è´¹ç”¨å æ¯”': '{:.1f}%', 'Vol': '{:.2f}'})
            .background_gradient(subset=['Fee'], cmap='Blues'),
            use_container_width=True
        )
        
        # Deep Dive
        with st.expander("ğŸ” å¼‚å¸¸åº“å­˜æ·±é’» (Top 20)", expanded=True):
            avail_ages = [l for l in (AGE_LABELS + ['360å¤©+']) if l in final_df['Age_Range'].unique()]
            if avail_ages:
                rng = st.radio("åº“é¾„æ®µ", avail_ages, horizontal=True, index=len(avail_ages)-1)
                drill = final_df[final_df['Age_Range'] == rng]
                top20 = drill.sort_values(by='Fee', ascending=False).head(20)
                st.dataframe(top20[['SKU','Warehouse','Qty','Fee','Age']], use_container_width=True)

    # ================= TAB 2: è¶‹åŠ¿åˆ†æ (æ ¸å¿ƒæ–°åŠŸèƒ½) =================
    with tab2:
        st.markdown("#### ğŸ“ˆ éƒ¨é—¨åº“å­˜/è´¹ç”¨èµ°åŠ¿å›¾")
        
        cc1, cc2 = st.columns(2)
        with cc1:
            # è¶‹åŠ¿ç­›é€‰
            t_dept = st.selectbox("åˆ†æéƒ¨é—¨", full_df['Dept'].unique(), key='t2_dept')
        with cc2:
            t_data = full_df[full_df['Dept'] == t_dept]
            t_prov = st.selectbox("åˆ†ææœåŠ¡å•†", t_data['Provider'].unique(), key='t2_prov')
            
        t_final = t_data[t_data['Provider'] == t_prov]
        
        # ä»“åº“ç»†åˆ†
        t_wh_list = sorted(t_final['Warehouse'].astype(str).unique().tolist())
        t_wh_list.insert(0, "å…¨éƒ¨æ±‡æ€»")
        t_wh = st.selectbox("åˆ†æä»“åº“ (å¯é€‰)", t_wh_list, key='t2_wh')
        
        if t_wh != "å…¨éƒ¨æ±‡æ€»":
            trend_source = t_final[t_final['Warehouse'] == t_wh]
        else:
            trend_source = t_final
            
        if len(trend_source['Date'].unique()) < 2:
            st.warning("âš ï¸ å½“å‰ç­›é€‰çš„æ•°æ®åªæœ‰ä¸€ä¸ªæœˆä»½ï¼Œæ— æ³•å±•ç¤ºè¶‹åŠ¿ã€‚è¯·ä¸Šä¼ æ›´å¤šæœˆä»½çš„æ–‡ä»¶ã€‚")
        else:
            # æ•°æ®èšåˆï¼šæŒ‰æ—¥æœŸåˆ†ç»„
            trend_agg = trend_source.groupby('Date').agg({
                'Fee': 'sum',
                'Vol': 'sum',
                'Qty': 'sum'
            }).reset_index().sort_values('Date')
            
            # 1. è´¹ç”¨ & ä½“ç§¯ åŒè½´è¶‹åŠ¿å›¾
            st.markdown("##### ğŸ’° è´¹ç”¨(Bar) ä¸ ä½“ç§¯(Line) å˜åŒ–")
            
            # ä½¿ç”¨ç®€å•çš„ Streamlit å›¾è¡¨ (ä¹Ÿå¯æ¢æˆ Altair æ›´é«˜çº§)
            chart_data = trend_agg.set_index('Date')[['Fee', 'Vol']]
            st.bar_chart(chart_data['Fee'], color='#FF4B4B') # çº¢è‰²æŸ±çŠ¶è¡¨ç¤ºè´¹ç”¨
            st.line_chart(chart_data['Vol'], color='#0000FF') # è“è‰²çº¿è¡¨ç¤ºä½“ç§¯
            
            # 2. å‘†æ»åº“å­˜ (360å¤©+) è¶‹åŠ¿
            st.markdown("##### âš ï¸ 360å¤©+ æåº¦å‘†æ»åº“å­˜è¶‹åŠ¿")
            dead_stock = trend_source[trend_source['Age_Range'] == '360å¤©+']
            if dead_stock.empty:
                st.success("è¯¥æ—¶é—´æ®µå†…æ—  360å¤©+ å‘†æ»åº“å­˜ï¼")
            else:
                dead_trend = dead_stock.groupby('Date')['Fee'].sum().reset_index().sort_values('Date')
                st.area_chart(dead_trend.set_index('Date'), color='#808080')
            
            # 3. æ•°æ®é€è§†è¡¨
            st.markdown("##### ğŸ“‹ è¯¦ç»†æ•°æ®å¯¹æ¯”")
            pivot = trend_agg.set_index('Date').T
            st.dataframe(pivot.style.format("{:,.2f}"), use_container_width=True)