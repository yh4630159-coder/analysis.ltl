import streamlit as st
import pandas as pd
import io
import altair as alt

# ================= 1. é…ç½®ä¸æ˜ å°„ =================
COLUMN_MAPS = {
    'WP': { 
        'SKU': 'SKU', 'Warehouse': 'ä»“åº“/Warehouse', 
        'Qty': 'æ•°é‡/Quantity', 'Fee': 'é‡‘é¢/Amount', 
        'Age': 'åº“é¾„/Library of Age', 'Vol': 'ä½“ç§¯(mÂ³)',
        'Full_Name': 'WesternPost'
    },
    'LG': { 
        'SKU': 'ä¹ä»“è´§å“ç¼–ç ', 'Warehouse': 'ä»“åº“', 
        'Qty': 'æ•°é‡', 'Fee': 'è®¡ç®—é‡‘é¢', 
        'Age': 'åº“é¾„', 'Vol': 'æ€»ä½“ç§¯',
        'Full_Name': 'Lecangs'
    },
    'AI': { 
        'SKU': 'SKU', 'Warehouse': 'ä»“åº“', 
        'Qty': 'åº“å­˜', 'Fee': 'è´¹ç”¨', 
        'Age': 'åœ¨åº“å¤©æ•°', 'Vol': 'ç«‹æ–¹æ•°',
        'Full_Name': 'AI'
    },
    'WL': { 
        'SKU': 'å•†å“SKU', 'Warehouse': 'å®é™…å‘è´§ä»“åº“', 
        'Qty': 'åº“å­˜æ€»æ•°_QTY', 'Fee': 'è®¡è´¹æ€»ä»·', 
        'Age': 'åº“å­˜åº“é¾„_CD', 'Vol': 'è®¡è´¹æ€»ä½“ç§¯_ç«‹æ–¹ç±³',
        'Full_Name': 'WWL'
    }
}

AGE_BINS = [0, 30, 60, 90, 120, 180, 360, 99999]
AGE_LABELS = ['0-30å¤©', '31-60å¤©', '61-90å¤©', '91-120å¤©', '120-180å¤©', '180-360å¤©', '360å¤©+']
AGE_MAP = {label: i for i, label in enumerate(AGE_LABELS)}

# ================= 2. æ ¸å¿ƒå¤„ç†é€»è¾‘ =================

def parse_filename(filename):
    name_body = filename.rsplit('.', 1)[0]
    parts = name_body.split('_')
    
    if len(parts) >= 3:
        dept = parts[0]
        raw_code = parts[1].upper()
        provider_code = None
        for key in COLUMN_MAPS.keys():
            if key in raw_code:
                provider_code = key
                break
        date_str = parts[2]
        return dept, provider_code, date_str
    return None, None, None

def load_data_v4(file):
    dept, provider_code, date_str = parse_filename(file.name)
    
    if not dept:
        dept = "é»˜è®¤éƒ¨é—¨"
        for code in COLUMN_MAPS.keys():
            if code in file.name.upper():
                provider_code = code
                break
        date_str = "æœ€æ–°"

    if not provider_code:
        st.toast(f"âš ï¸ è·³è¿‡æœªçŸ¥æ–‡ä»¶: {file.name}", icon="â­ï¸")
        return pd.DataFrame()

    df = None
    try: df = pd.read_excel(file, engine='openpyxl', header=None); 
    except: pass
    if df is None:
        try: file.seek(0); df = pd.read_csv(file, encoding='utf-8', header=None)
        except: pass
    if df is None:
        try: file.seek(0); df = pd.read_csv(file, encoding='gb18030', header=None)
        except: pass
            
    if df is None:
        return pd.DataFrame()

    try:
        mapping = COLUMN_MAPS[provider_code]
        
        header_idx = 0
        expected_cols = set(mapping.values())
        expected_cols.discard(mapping.get('Full_Name'))
        
        for i in range(min(20, len(df))):
            row_values = df.iloc[i].astype(str).str.strip().tolist()
            row_values = [x.replace('\ufeff', '') for x in row_values]
            match_count = sum(1 for x in row_values if x in expected_cols)
            if match_count >= 2:
                header_idx = i
                break
        
        new_columns = df.iloc[header_idx].astype(str).str.strip().str.replace('\ufeff', '')
        df = df.iloc[header_idx+1:].copy()
        df.columns = new_columns

        valid_map = {k: v for k, v in mapping.items() if v in df.columns}
        rename_dict = {v: k for k, v in valid_map.items()}
        df = df.rename(columns=rename_dict)
        
        required_cols = ['SKU', 'Warehouse', 'Qty', 'Fee', 'Age', 'Vol']
        for col in required_cols:
            if col not in df.columns: df[col] = 0 
                
        for col in ['Qty', 'Fee', 'Age', 'Vol']:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
        cut_series = pd.cut(df['Age'], bins=AGE_BINS, labels=AGE_LABELS, right=False)
        df['Age_Range'] = cut_series.astype(str)
        df.loc[df['Age_Range'] == 'nan', 'Age_Range'] = '360å¤©+'
        df['Age_Range'] = df['Age_Range'].str.strip()

        df['Dept'] = dept
        df['Provider'] = mapping['Full_Name']
        df['Date'] = date_str
        
        return df
        
    except Exception as e:
        return pd.DataFrame()

# ================= 3. ç•Œé¢é€»è¾‘ =================
st.set_page_config(page_title="æµ·å¤–ä»“åº“å­˜ BI V4.0", page_icon="ğŸŒ", layout="wide")
st.title("ğŸŒ æµ·å¤–ä»“åº“å­˜åˆ†æçœ‹æ¿ V4.0 (ä¸Šå¸è§†è§’ç‰ˆ)")

with st.expander("â„¹ï¸ æ–‡ä»¶å‘½åè§„èŒƒ", expanded=False):
    st.markdown("è¯·å°†æ–‡ä»¶é‡å‘½åä¸ºï¼š**`éƒ¨é—¨_æœåŠ¡å•†_æ—¥æœŸ.xlsx`** (ä¾‹å¦‚: `ä¸šåŠ¡ä¸€éƒ¨_AI_2024-01.xlsx`)")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ“‚ æ•°æ®ä¸­å¿ƒ")
    uploaded_files = st.file_uploader("æ‰¹é‡ä¸Šä¼ æ–‡ä»¶", type=['xlsx', 'xls', 'csv'], accept_multiple_files=True)
    
    dfs = []
    if uploaded_files:
        for file in uploaded_files:
            df = load_data_v4(file)
            if not df.empty:
                dfs.append(df)
        st.success(f"å·²åŠ è½½ {len(dfs)} ä¸ªæ–‡ä»¶")

if not dfs:
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¼€å§‹åˆ†æ")
else:
    full_df = pd.concat(dfs, ignore_index=True)
    
    tab1, tab2 = st.tabs(["ğŸ“Š å…¨æ™¯è¯¦æƒ… (SKUçº§)", "ğŸ†š å†å²è¶‹åŠ¿ & é£é™©æ´å¯Ÿ"])
    
    # ================= TAB 1: å…¨æ™¯è¯¦æƒ… (ä¸‰çº§å…¨æ±‡æ€») =================
    with tab1:
        # --- 1. éƒ¨é—¨é€‰æ‹© ---
        # é€»è¾‘ï¼šå…ˆæ‹¿å‡ºæ‰€æœ‰éƒ¨é—¨ï¼Œå‰é¢åŠ ä¸€ä¸ªâ€œå…¨éƒ¨æ±‡æ€»â€
        all_depts = sorted(full_df['Dept'].unique().tolist())
        all_depts.insert(0, "å…¨éƒ¨æ±‡æ€»")
        
        c1, c2, c3, c4 = st.columns(4)
        with c1: 
            sel_dept = st.selectbox("â‘  é€‰æ‹©éƒ¨é—¨", all_depts, key='t1_d')
            
        # æ ¹æ®éƒ¨é—¨ç­›é€‰æ•°æ®æ±  (Level 1 Filter)
        if sel_dept == "å…¨éƒ¨æ±‡æ€»":
            df_l1 = full_df
        else:
            df_l1 = full_df[full_df['Dept'] == sel_dept]

        # --- 2. æ—¥æœŸé€‰æ‹© ---
        # é€»è¾‘ï¼šæ—¥æœŸä¸€èˆ¬æ˜¯å•é€‰ï¼Œä¸ºäº†çœ‹ç‰¹å®šæœˆä»½çš„æŠ¥è¡¨
        avail_dates = sorted(df_l1['Date'].unique(), reverse=True)
        with c2: 
            sel_date = st.selectbox("â‘¡ é€‰æ‹©æœˆä»½", avail_dates, key='t1_dt')
            
        # æ ¹æ®æ—¥æœŸç­›é€‰æ•°æ®æ±  (Time Filter)
        df_l2 = df_l1[df_l1['Date'] == sel_date]

        # --- 3. æœåŠ¡å•†é€‰æ‹© ---
        # é€»è¾‘ï¼šåŸºäºå½“å‰å‰©ä¸‹çš„æ•°æ®ï¼Œçœ‹æœ‰å“ªäº›æœåŠ¡å•†
        avail_provs = sorted(df_l2['Provider'].unique().tolist())
        avail_provs.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with c3: 
            sel_prov = st.selectbox("â‘¢ é€‰æ‹©æœåŠ¡å•†", avail_provs, key='t1_p')
            
        # æ ¹æ®æœåŠ¡å•†ç­›é€‰æ•°æ®æ±  (Level 2 Filter)
        if sel_prov == "å…¨éƒ¨æ±‡æ€»":
            df_l3 = df_l2
        else:
            df_l3 = df_l2[df_l2['Provider'] == sel_prov]
            
        # --- 4. ä»“åº“é€‰æ‹© ---
        # é€»è¾‘ï¼šåŸºäºå½“å‰å‰©ä¸‹çš„æ•°æ®ï¼Œçœ‹æœ‰å“ªäº›ä»“åº“
        avail_whs = sorted(df_l3['Warehouse'].astype(str).unique().tolist())
        avail_whs.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with c4: 
            sel_wh = st.selectbox("â‘£ é€‰æ‹©ä»“åº“", avail_whs, key='t1_w')
            
        # æœ€ç»ˆæ•°æ® (Final Filter)
        if sel_wh == "å…¨éƒ¨æ±‡æ€»":
            final_df = df_l3
        else:
            final_df = df_l3[df_l3['Warehouse'] == sel_wh]
            
        # ---------------- é¡µé¢å±•ç¤º ----------------
        
        # æ ‡é¢˜åŠ¨æ€æ˜¾ç¤º
        st.markdown(f"### ğŸ“‹ æ•°æ®è§†å›¾ï¼š{sel_dept} Â· {sel_prov} Â· {sel_wh}")

        # ç»Ÿè®¡ KPI
        k1, k2, k3 = st.columns(3)
        k1.metric("æ€»åº“å­˜ (Qty)", f"{final_df['Qty'].sum():,.0f}")
        k2.metric("æ€»ä½“ç§¯ (Vol)", f"{final_df['Vol'].sum():,.2f} mÂ³")
        k3.metric("æ€»è´¹ç”¨ (Fee)", f"${final_df['Fee'].sum():,.2f}")
        
        # åº“é¾„ç»“æ„è¡¨
        summary = final_df.groupby('Age_Range').agg({'Fee':'sum','Qty':'sum','Vol':'sum'}).reset_index()
        order_map = {l: i for i, l in enumerate(AGE_LABELS)}
        summary['sort'] = summary['Age_Range'].map(order_map).fillna(999)
        summary = summary.sort_values('sort').drop('sort', axis=1)
        summary['è´¹ç”¨å æ¯”'] = (summary['Fee']/final_df['Fee'].sum()*100).fillna(0)
        
        st.dataframe(summary.style.format({'Fee':'${:.2f}','è´¹ç”¨å æ¯”':'{:.1f}%'}), use_container_width=True)
        
        # Top 20 æ·±é’»
        st.divider()
        st.markdown("#### ğŸ” å¼‚å¸¸åº“å­˜æ·±é’»")
        
        valid_ages = [l for l in AGE_LABELS if l in final_df['Age_Range'].unique()]
        if valid_ages:
            r_col1, r_col2 = st.columns([3, 1])
            with r_col1:
                rng = st.radio("é€‰æ‹©åº“é¾„æ®µ", valid_ages, horizontal=True, index=len(valid_ages)-1, key='t1_r')
            
            drill = final_df[final_df['Age_Range'] == rng].copy()
            
            # åˆ¤æ–­æ˜¯å¦å¼€å¯èšåˆï¼šåªè¦éƒ¨é—¨ã€æœåŠ¡å•†ã€ä»“åº“ä»»ä¸€é€‰äº†â€œå…¨éƒ¨â€ï¼Œå°±å¯ä»¥å¼€å¯èšåˆ
            is_any_all_selected = (sel_dept == "å…¨éƒ¨æ±‡æ€»") or (sel_prov == "å…¨éƒ¨æ±‡æ€»") or (sel_wh == "å…¨éƒ¨æ±‡æ€»")
            
            show_agg = False
            if is_any_all_selected:
                with r_col2:
                    st.write("")
                    st.write("") 
                    # åŠ¨æ€æ–‡æ¡ˆ
                    help_text = "å°†åŒä¸€ SKU çš„æ•°æ®åˆå¹¶æ˜¾ç¤ºï¼ˆè´¹ç”¨å åŠ ï¼‰ã€‚"
                    show_agg = st.checkbox("ğŸ”€ SKU å®è§‚èšåˆ", value=True, help=help_text, key="chk_agg_mode")
            
            if drill.empty:
                st.info("æ— æ•°æ®")
            else:
                if show_agg:
                    try:
                        # å¼ºè½¬æ•°å­—é˜²æ­¢æŠ¥é”™
                        for col in ['Qty', 'Vol', 'Fee', 'Age']:
                            drill[col] = pd.to_numeric(drill[col], errors='coerce').fillna(0)
                        
                        # 1. èšåˆ (æ³¨æ„ï¼šå¦‚æœé€‰äº†å…¨éƒ¨éƒ¨é—¨ï¼Œè¿™é‡Œä¼šæŠŠä¸åŒéƒ¨é—¨çš„åŒSKUä¹ŸåŠ ä¸Š)
                        agg_sku = drill.groupby('SKU').agg({
                            'Qty': 'sum',
                            'Vol': 'sum',
                            'Fee': 'sum',
                            'Age': 'mean',
                            'Warehouse': 'nunique',
                            'Dept': 'nunique',     # ç»Ÿè®¡æ¶‰åŠå‡ ä¸ªéƒ¨é—¨
                            'Provider': 'nunique'  # ç»Ÿè®¡æ¶‰åŠå‡ ä¸ªæœåŠ¡å•†
                        }).reset_index()
                        
                        top20 = agg_sku.sort_values('Fee', ascending=False).head(20)
                        
                        # æ„å»ºæè¿°ä¿¡æ¯
                        def build_info(row):
                            infos = []
                            if sel_dept == "å…¨éƒ¨æ±‡æ€»" and row['Dept'] > 1: infos.append(f"{row['Dept']}ä¸ªéƒ¨é—¨")
                            if sel_prov == "å…¨éƒ¨æ±‡æ€»" and row['Provider'] > 1: infos.append(f"{row['Provider']}ä¸ªæœåŠ¡å•†")
                            infos.append(f"{row['Warehouse']}ä¸ªä»“")
                            return " | ".join(infos)

                        top20['åˆ†å¸ƒ'] = top20.apply(build_info, axis=1)
                        
                        top20_show = top20[['SKU', 'åˆ†å¸ƒ', 'Qty', 'Vol', 'Fee', 'Age']].copy()
                        top20_show.columns = ['SKU', 'åˆ†å¸ƒæƒ…å†µ', 'æ€»åº“å­˜', 'æ€»ä½“ç§¯', 'æ€»è´¹ç”¨(å åŠ )', 'å¹³å‡åº“é¾„']
                        
                        st.success(f"ğŸ“Š å®è§‚è§†è§’å·²å¼€å¯ï¼šæ­£åœ¨æŸ¥çœ‹ **{sel_dept}** - **{sel_prov}** èŒƒå›´å†…çš„ SKU ç»¼åˆè¡¨ç°ã€‚")
                        
                        st.dataframe(
                            top20_show.style.format({
                                'æ€»è´¹ç”¨(å åŠ )': '${:.2f}', 
                                'å¹³å‡åº“é¾„': '{:.0f}',
                                'æ€»ä½“ç§¯': '{:.2f}'
                            }).background_gradient(subset=['æ€»è´¹ç”¨(å åŠ )'], cmap='Reds'), 
                            use_container_width=True
                        )
                    except Exception as e:
                        st.error(f"èšåˆè®¡ç®—å‡ºé”™: {str(e)}")
                        st.dataframe(drill.head(20))
                else:
                    # åŸå§‹æ˜ç»†æ¨¡å¼
                    cols_show = ['SKU', 'Warehouse', 'Qty', 'Vol', 'Fee', 'Age']
                    # å¦‚æœé€‰äº†å…¨éƒ¨éƒ¨é—¨ï¼Œæœ€å¥½æŠŠéƒ¨é—¨å’ŒæœåŠ¡å•†ä¹Ÿå±•ç¤ºå‡ºæ¥
                    if sel_dept == "å…¨éƒ¨æ±‡æ€»": cols_show.insert(1, 'Dept')
                    if sel_prov == "å…¨éƒ¨æ±‡æ€»": cols_show.insert(2, 'Provider')
                    
                    top20 = drill.sort_values('Fee', ascending=False).head(20)[cols_show]
                    try:
                        st.dataframe(top20.style.format({'Fee':'${:.2f}', 'Vol': '{:.2f}'}).background_gradient(subset=['Fee'], cmap='Reds'), use_container_width=True)
                    except:
                        st.dataframe(top20, use_container_width=True)
        else:
            st.warning("æ— æ•°æ®")

    # ================= TAB 2: è¶‹åŠ¿å¯¹æ¯” (é€‚é…å…¨æ™¯é€»è¾‘) =================
    with tab2:
        st.markdown("#### ğŸ†š å†å²è¶‹åŠ¿ & é£é™©æ´å¯Ÿ")
        
        # åŒæ ·çš„çº§è”é€»è¾‘
        cc1, cc2, cc3 = st.columns(3)
        
        # 1. éƒ¨é—¨
        all_depts_t = sorted(full_df['Dept'].unique().tolist())
        all_depts_t.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with cc1: t_dept = st.selectbox("åˆ†æéƒ¨é—¨", all_depts_t, key='t2_d')
        
        df_t1 = full_df if t_dept == "å…¨éƒ¨æ±‡æ€»" else full_df[full_df['Dept'] == t_dept]

        # 2. æœåŠ¡å•†
        all_provs_t = sorted(df_t1['Provider'].unique().tolist())
        all_provs_t.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with cc2: t_prov = st.selectbox("åˆ†ææœåŠ¡å•†", all_provs_t, key='t2_p')
        
        df_t2 = df_t1 if t_prov == "å…¨éƒ¨æ±‡æ€»" else df_t1[df_t1['Provider'] == t_prov]

        # 3. ä»“åº“
        all_whs_t = sorted(df_t2['Warehouse'].astype(str).unique().tolist())
        all_whs_t.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with cc3: t_wh = st.selectbox("åˆ†æä»“åº“", all_whs_t, key='t2_w')
        
        t_final = df_t2 if t_wh == "å…¨éƒ¨æ±‡æ€»" else df_t2[df_t2['Warehouse'] == t_wh]
        
        # --- ä¸‹é¢çš„å›¾è¡¨é€»è¾‘ä¸éœ€è¦å˜ï¼Œå› ä¸º t_final å·²ç»æ˜¯ç­›é€‰å¥½çš„äº† ---
        available_dates = sorted(t_final['Date'].unique())
        selected_dates = st.multiselect("é€‰æ‹©åˆ†ææœˆä»½", available_dates, default=available_dates)
        
        if not selected_dates:
            st.warning("è¯·é€‰æ‹©æœˆä»½ã€‚")
        else:
            chart_df = t_final[t_final['Date'].isin(selected_dates)]
            
            # KPI
            st.divider()
            latest_month = sorted(selected_dates)[-1]
            latest_data = t_final[t_final['Date'] == latest_month]
            
            dead_fee = latest_data[latest_data['Age_Range'] == '360å¤©+']['Fee'].sum()
            total_fee = latest_data['Fee'].sum()
            total_qty = latest_data['Qty'].sum()
            cpu = total_fee / total_qty if total_qty > 0 else 0
            
            kp1, kp2, kp3 = st.columns(3)
            kp1.metric(f"{latest_month} æ€»ä»“ç§Ÿ", f"${total_fee:,.0f}")
            kp2.metric(f"ğŸ“‰ å•ä½ä»“ç§Ÿæˆæœ¬", f"${cpu:.3f} /ä»¶")
            kp3.metric(f"ğŸ’° 360å¤©+æ½œåœ¨èŠ‚çœ", f"${dead_fee:,.0f}")
            
            st.divider()

            # å›¾è¡¨
            agg_df = chart_df.groupby(['Date', 'Age_Range']).agg({
                'Qty': 'sum', 'Fee': 'sum', 'Vol': 'sum'
            }).reset_index()
            
            st.markdown("##### ğŸ“¦ å„åº“é¾„æ®µåº“å­˜é‡å¯¹æ¯”")
            base_chart = alt.Chart(agg_df).encode(
                x=alt.X('Age_Range', sort=AGE_LABELS, title="åº“é¾„åˆ†æ®µ"),
                y=alt.Y('Qty', title="åº“å­˜æ•°é‡"),
                color=alt.Color('Date', title="æœˆä»½"),
                tooltip=['Date', 'Age_Range', 'Qty']
            )
            grouped_bar = base_chart.mark_bar().encode(xOffset='Date').properties(height=350)
            st.altair_chart(grouped_bar, use_container_width=True)
            
            c_fee, c_cpu = st.columns(2)
            with c_fee:
                st.markdown("##### ğŸ’° è´¹ç”¨ç»“æ„")
                fee_pivot = agg_df.pivot(index='Date', columns='Age_Range', values='Fee')
                sorted_cols = [c for c in AGE_LABELS if c in fee_pivot.columns]
                st.bar_chart(fee_pivot[sorted_cols])
            
            with c_cpu:
                st.markdown("##### ğŸ“‰ å•ä½ä»“ç§Ÿæˆæœ¬è¶‹åŠ¿")
                cpu_trend = chart_df.groupby('Date').apply(
                    lambda x: pd.Series({'CPU': x['Fee'].sum() / x['Qty'].sum() if x['Qty'].sum() > 0 else 0})
                ).reset_index()
                
                cpu_chart = alt.Chart(cpu_trend).mark_line(point=True).encode(
                    x='Date',
                    y=alt.Y('CPU', title='å•ä»¶æˆæœ¬ ($)'),
                    tooltip=['Date', alt.Tooltip('CPU', format='.3f')]
                ).properties(height=300)
                st.altair_chart(cpu_chart, use_container_width=True)

            # æ¶åŒ–é¢„è­¦
            st.divider()
            st.markdown("#### ğŸš¨ åº“å­˜æ¶åŒ–ç›‘æ§")
            if len(selected_dates) >= 2:
                sorted_dates = sorted(selected_dates)
                curr_month = sorted_dates[-1]
                prev_month = sorted_dates[-2]
                
                # èšåˆæ—¶éœ€åŒ…å« Dept å’Œ Provider é˜²æ­¢ SKU é‡å¤
                group_cols = ['SKU', 'Warehouse', 'Dept', 'Provider']
                
                df_curr = chart_df[chart_df['Date'] == curr_month][group_cols + ['Age_Range', 'Fee']]
                df_prev = chart_df[chart_df['Date'] == prev_month][group_cols + ['Age_Range']]
                
                merged = pd.merge(df_prev, df_curr, on=group_cols, suffixes=('_old', '_new'))
                merged['idx_old'] = merged['Age_Range_old'].map(AGE_MAP).fillna(-1)
                merged['idx_new'] = merged['Age_Range_new'].map(AGE_MAP).fillna(-1)
                
                worsened = merged[merged['idx_new'] > merged['idx_old']].copy()
                
                if worsened.empty:
                    st.success("ğŸ‰ æ— åº“å­˜æ¶åŒ–ã€‚")
                else:
                    worsened['Fee'] = worsened['Fee'].astype(float)
                    top_worsened = worsened.sort_values('Fee', ascending=False).head(20)
                    
                    st.dataframe(
                        top_worsened[['SKU', 'Dept', 'Warehouse', 'Age_Range_old', 'Age_Range_new', 'Fee']]
                        .rename(columns={'Age_Range_old': f'{prev_month} åº“é¾„', 'Age_Range_new': f'{curr_month} åº“é¾„', 'Fee': 'å½“å‰ä»“ç§Ÿ($)'})
                        .style.format({'å½“å‰ä»“ç§Ÿ($)': '${:.2f}'})
                        .background_gradient(subset=['å½“å‰ä»“ç§Ÿ($)'], cmap='Reds'),
                        use_container_width=True
                    )
            else:
                st.info("ğŸ’¡ è¯·é€‰æ‹©è‡³å°‘ 2 ä¸ªæœˆä»½ä»¥å¯ç”¨æ¶åŒ–ç›‘æ§ã€‚")