import streamlit as st
import pandas as pd
import io
import altair as alt
import gc  # åƒåœ¾å›æ”¶

# ================= 1. é…ç½®ä¸æ˜ å°„ =================
COLUMN_MAPS = {
    'WP': { 
        'SKU': 'SKU', 'Warehouse': 'ä»“åº“/Warehouse', 
        'Qty': 'æ•°é‡/Quantity', 'Fee': 'é‡‘é¢/Amount', 
        'Age': 'åº“é¾„/Library of Age', 'Vol': 'ä½“ç§¯(mÂ³)',
        'Full_Name': 'WesternPost'
    },
    'LG': { 
        'SKU': 'ä¹ä»“è´§å“ç¼–ç ', 'Warehouse': 'ä»“åº“', 
        'Qty': 'æ•°é‡', 'Fee': 'è®¡ç®—é‡‘é¢', 
        'Age': 'åº“é¾„', 'Vol': 'æ€»ä½“ç§¯',
        'Full_Name': 'Lecangs'
    },
    'AI': { 
        'SKU': 'SKU', 'Warehouse': 'ä»“åº“', 
        'Qty': 'åº“å­˜', 'Fee': 'è´¹ç”¨', 
        'Age': 'åœ¨åº“å¤©æ•°', 'Vol': 'ç«‹æ–¹æ•°',
        'Full_Name': 'AI'
    },
    'WL': { 
        'SKU': 'å•†å“SKU', 'Warehouse': 'å®é™…å‘è´§ä»“åº“', 
        'Qty': 'åº“å­˜æ€»æ•°_QTY', 'Fee': 'è®¡è´¹æ€»ä»·', 
        'Age': 'åº“å­˜åº“é¾„_CD', 'Vol': 'è®¡è´¹æ€»ä½“ç§¯_ç«‹æ–¹ç±³',
        'Full_Name': 'WWL'
    }
}

AGE_BINS = [0, 30, 60, 90, 120, 180, 360, 99999]
AGE_LABELS = ['0-30å¤©', '31-60å¤©', '61-90å¤©', '91-120å¤©', '120-180å¤©', '180-360å¤©', '360å¤©+']
AGE_MAP = {label: i for i, label in enumerate(AGE_LABELS)}

# ================= 2. æ ¸å¿ƒå¤„ç†é€»è¾‘ (ç¨³å®šç¼“å­˜ç‰ˆ) =================

def parse_filename(filename):
    name_body = filename.rsplit('.', 1)[0]
    parts = name_body.split('_')
    if len(parts) >= 3:
        dept = parts[0]
        raw_code = parts[1].upper()
        provider_code = None
        for key in COLUMN_MAPS.keys():
            if key in raw_code:
                provider_code = key
                break
        date_str = parts[2]
        return dept, provider_code, date_str
    return None, None, None

# ğŸš€ ä¼˜åŒ–æ ¸å¿ƒï¼šä½¿ç”¨ç¼“å­˜ï¼Œä½†è¿”å›æ ‡å‡†æ•°æ®ç±»å‹
@st.cache_data(ttl=3600, show_spinner=False)
def load_single_file(file_content, file_name):
    file = io.BytesIO(file_content)
    file.name = file_name

    dept, provider_code, date_str = parse_filename(file.name)
    
    # æ¨¡ç³ŠåŒ¹é…é€»è¾‘
    if not dept:
        dept = "é»˜è®¤éƒ¨é—¨"
        for code in COLUMN_MAPS.keys():
            if code in file.name.upper():
                provider_code = code
                break
        date_str = "æœ€æ–°"

    if not provider_code:
        return pd.DataFrame()

    df = None
    try: df = pd.read_excel(file, engine='openpyxl', header=None); 
    except: pass
    if df is None:
        try: file.seek(0); df = pd.read_csv(file, encoding='utf-8', header=None)
        except: pass
    if df is None:
        try: file.seek(0); df = pd.read_csv(file, encoding='gb18030', header=None)
        except: pass
            
    if df is None:
        return pd.DataFrame()

    try:
        mapping = COLUMN_MAPS[provider_code]
        
        # æ™ºèƒ½è¡¨å¤´ (åŠ é€Ÿæ‰«æ)
        header_idx = 0
        expected_cols = set(mapping.values())
        expected_cols.discard(mapping.get('Full_Name'))
        
        for i in range(min(15, len(df))):
            row_values = df.iloc[i].astype(str).str.strip().tolist()
            row_values = [x.replace('\ufeff', '') for x in row_values]
            match_count = sum(1 for x in row_values if x in expected_cols)
            if match_count >= 2:
                header_idx = i
                break
        
        new_columns = df.iloc[header_idx].astype(str).str.strip().str.replace('\ufeff', '')
        df = df.iloc[header_idx+1:].copy()
        df.columns = new_columns

        valid_map = {k: v for k, v in mapping.items() if v in df.columns}
        rename_dict = {v: k for k, v in valid_map.items()}
        df = df.rename(columns=rename_dict)
        
        # åªä¿ç•™æœ‰ç”¨åˆ—
        required_cols = ['SKU', 'Warehouse', 'Qty', 'Fee', 'Age', 'Vol']
        cols_to_keep = [c for c in required_cols if c in df.columns]
        df = df[cols_to_keep]

        for col in required_cols:
            if col not in df.columns: df[col] = 0 
                
        # ğŸŒŸ ä¿®å¤ç‚¹ï¼šä½¿ç”¨æ ‡å‡† float ç±»å‹ï¼Œä¸å¼ºåˆ¶å‹ç¼© float32ï¼Œé˜²æ­¢ç”»å›¾æŠ¥é”™
        for col in ['Qty', 'Fee', 'Age', 'Vol']:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
        cut_series = pd.cut(df['Age'], bins=AGE_BINS, labels=AGE_LABELS, right=False)
        df['Age_Range'] = cut_series.astype(str)
        df.loc[df['Age_Range'] == 'nan', 'Age_Range'] = '360å¤©+'
        df['Age_Range'] = df['Age_Range'].str.strip()
        
        df['Dept'] = dept
        df['Provider'] = mapping['Full_Name']
        df['Date'] = date_str
        
        gc.collect() # ä¾ç„¶ä¿ç•™åƒåœ¾å›æ”¶
        return df
        
    except Exception as e:
        return pd.DataFrame()

# ================= 3. ç•Œé¢é€»è¾‘ =================
st.set_page_config(page_title="æµ·å¤–ä»“åº“å­˜ BI V4.2", page_icon="ğŸ›¡ï¸", layout="wide")
st.title("ğŸ›¡ï¸ æµ·å¤–ä»“åº“å­˜åˆ†æçœ‹æ¿ V4.2 (ç¨³å®šä¿®æ­£ç‰ˆ)")

with st.expander("â„¹ï¸ ä½¿ç”¨è´´å£«", expanded=False):
    st.markdown("æ”¯æŒæ‰¹é‡ä¸Šä¼  20+ æ–‡ä»¶ã€‚é¦–æ¬¡è§£æéœ€ç­‰å¾…ï¼Œåç»­æ“ä½œå°†ç”±ç¼“å­˜åŠ é€Ÿã€‚")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("ğŸ“‚ æ•°æ®ä¸­å¿ƒ")
    uploaded_files = st.file_uploader("æ‰¹é‡ä¸Šä¼ æ–‡ä»¶", type=['xlsx', 'xls', 'csv'], accept_multiple_files=True)
    
    if st.button("ğŸ§¹ åˆ·æ–°ç¼“å­˜"):
        st.cache_data.clear()
        st.success("å·²åˆ·æ–°")

    dfs = []
    if uploaded_files:
        progress_text = "æ­£åœ¨è§£ææ–‡ä»¶ï¼Œè¯·ç¨å€™..."
        my_bar = st.progress(0, text=progress_text)
        
        for i, file in enumerate(uploaded_files):
            bytes_data = file.getvalue()
            df = load_single_file(bytes_data, file.name)
            
            if not df.empty:
                dfs.append(df)
            
            my_bar.progress((i + 1) / len(uploaded_files), text=f"è¿›åº¦: {i+1}/{len(uploaded_files)}")
            
        my_bar.empty()
        st.success(f"âœ… æˆåŠŸåŠ è½½ {len(dfs)} ä¸ªæ–‡ä»¶")

if not dfs:
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼ æ•°æ®æ–‡ä»¶")
else:
    full_df = pd.concat(dfs, ignore_index=True)
    
    # è½¬ Category ä¾ç„¶ä¿ç•™ï¼Œè¿™æ˜¯å®‰å…¨çš„å†…å­˜ä¼˜åŒ–
    for col in ['Dept', 'Provider', 'Warehouse', 'Date', 'Age_Range']:
        full_df[col] = full_df[col].astype('category')

    tab1, tab2 = st.tabs(["ğŸ“Š å…¨æ™¯è¯¦æƒ… (SKUçº§)", "ğŸ†š å†å²è¶‹åŠ¿ & é£é™©æ´å¯Ÿ"])
    
    # ================= TAB 1: å…¨æ™¯è¯¦æƒ… =================
    with tab1:
        # ç­›é€‰é€»è¾‘
        all_depts = sorted(full_df['Dept'].unique().tolist())
        all_depts.insert(0, "å…¨éƒ¨æ±‡æ€»")
        
        c1, c2, c3, c4 = st.columns(4)
        with c1: sel_dept = st.selectbox("â‘  é€‰æ‹©éƒ¨é—¨", all_depts, key='t1_d')
        df_l1 = full_df if sel_dept == "å…¨éƒ¨æ±‡æ€»" else full_df[full_df['Dept'] == sel_dept]

        avail_dates = sorted(df_l1['Date'].unique(), reverse=True)
        with c2: sel_date = st.selectbox("â‘¡ é€‰æ‹©æœˆä»½", avail_dates, key='t1_dt')
        df_l2 = df_l1[df_l1['Date'] == sel_date]

        avail_provs = sorted(df_l2['Provider'].unique().tolist())
        avail_provs.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with c3: sel_prov = st.selectbox("â‘¢ é€‰æ‹©æœåŠ¡å•†", avail_provs, key='t1_p')
        df_l3 = df_l2 if sel_prov == "å…¨éƒ¨æ±‡æ€»" else df_l2[df_l2['Provider'] == sel_prov]
            
        avail_whs = sorted(df_l3['Warehouse'].astype(str).unique().tolist())
        avail_whs.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with c4: sel_wh = st.selectbox("â‘£ é€‰æ‹©ä»“åº“", avail_whs, key='t1_w')
        
        final_df = df_l3 if sel_wh == "å…¨éƒ¨æ±‡æ€»" else df_l3[df_l3['Warehouse'] == sel_wh]
            
        st.markdown(f"### ğŸ“‹ æ•°æ®è§†å›¾ï¼š{sel_dept} Â· {sel_prov} Â· {sel_wh}")

        k1, k2, k3 = st.columns(3)
        k1.metric("æ€»åº“å­˜", f"{final_df['Qty'].sum():,.0f}")
        k2.metric("æ€»ä½“ç§¯", f"{final_df['Vol'].sum():,.2f} mÂ³")
        k3.metric("æ€»è´¹ç”¨", f"${final_df['Fee'].sum():,.2f}")
        
        # èšåˆæ—¶éœ€å¤„ç† category
        summary = final_df.groupby('Age_Range', observed=True).agg({'Fee':'sum','Qty':'sum','Vol':'sum'}).reset_index()
        order_map = {l: i for i, l in enumerate(AGE_LABELS)}
        summary['sort'] = summary['Age_Range'].map(order_map).fillna(999)
        summary = summary.sort_values('sort').drop('sort', axis=1)
        summary['è´¹ç”¨å æ¯”'] = (summary['Fee']/final_df['Fee'].sum()*100).fillna(0)
        
        st.dataframe(summary.style.format({'Fee':'${:.2f}','è´¹ç”¨å æ¯”':'{:.1f}%'}), use_container_width=True)
        
        st.divider()
        st.markdown("#### ğŸ” å¼‚å¸¸åº“å­˜æ·±é’»")
        
        valid_ages = [l for l in AGE_LABELS if l in final_df['Age_Range'].unique()]
        if valid_ages:
            r_col1, r_col2 = st.columns([3, 1])
            with r_col1:
                rng = st.radio("é€‰æ‹©åº“é¾„æ®µ", valid_ages, horizontal=True, index=len(valid_ages)-1, key='t1_r')
            
            drill = final_df[final_df['Age_Range'] == rng].copy()
            
            is_any_all_selected = (sel_dept == "å…¨éƒ¨æ±‡æ€»") or (sel_prov == "å…¨éƒ¨æ±‡æ€»") or (sel_wh == "å…¨éƒ¨æ±‡æ€»")
            
            show_agg = False
            if is_any_all_selected:
                with r_col2:
                    st.write("")
                    st.write("") 
                    show_agg = st.checkbox("ğŸ”€ SKU å®è§‚èšåˆ", value=True, key="chk_agg_mode")
            
            if drill.empty:
                st.info("æ— æ•°æ®")
            else:
                if show_agg:
                    try:
                        # ç¡®ä¿æ˜¯æ ‡å‡†æ•°å­—ç±»å‹
                        for col in ['Qty', 'Vol', 'Fee', 'Age']:
                            drill[col] = pd.to_numeric(drill[col], errors='coerce').fillna(0)
                        
                        agg_sku = drill.groupby('SKU', observed=True).agg({
                            'Qty': 'sum', 'Vol': 'sum', 'Fee': 'sum', 'Age': 'mean',
                            'Warehouse': 'nunique', 'Dept': 'nunique', 'Provider': 'nunique'
                        }).reset_index()
                        
                        top20 = agg_sku.sort_values('Fee', ascending=False).head(20)
                        
                        def build_info(row):
                            infos = []
                            if sel_dept == "å…¨éƒ¨æ±‡æ€»" and row['Dept'] > 1: infos.append(f"{row['Dept']}ä¸ªéƒ¨é—¨")
                            if sel_prov == "å…¨éƒ¨æ±‡æ€»" and row['Provider'] > 1: infos.append(f"{row['Provider']}ä¸ªæœåŠ¡å•†")
                            infos.append(f"{row['Warehouse']}ä¸ªä»“")
                            return " | ".join(infos)

                        top20['åˆ†å¸ƒ'] = top20.apply(build_info, axis=1)
                        top20_show = top20[['SKU', 'åˆ†å¸ƒ', 'Qty', 'Vol', 'Fee', 'Age']]
                        top20_show.columns = ['SKU', 'åˆ†å¸ƒæƒ…å†µ', 'æ€»åº“å­˜', 'æ€»ä½“ç§¯', 'æ€»è´¹ç”¨(å åŠ )', 'å¹³å‡åº“é¾„']
                        
                        st.dataframe(top20_show.style.format({'æ€»è´¹ç”¨(å åŠ )': '${:.2f}', 'å¹³å‡åº“é¾„': '{:.0f}', 'æ€»ä½“ç§¯': '{:.2f}'}).background_gradient(subset=['æ€»è´¹ç”¨(å åŠ )'], cmap='Reds'), use_container_width=True)
                    except Exception as e:
                        st.error(f"èšåˆå‡ºé”™: {str(e)}")
                else:
                    cols_show = ['SKU', 'Warehouse', 'Qty', 'Vol', 'Fee', 'Age']
                    if sel_dept == "å…¨éƒ¨æ±‡æ€»": cols_show.insert(1, 'Dept')
                    if sel_prov == "å…¨éƒ¨æ±‡æ€»": cols_show.insert(2, 'Provider')
                    top20 = drill.sort_values('Fee', ascending=False).head(20)[cols_show]
                    st.dataframe(top20.style.format({'Fee':'${:.2f}', 'Vol': '{:.2f}'}).background_gradient(subset=['Fee'], cmap='Reds'), use_container_width=True)
        else:
            st.warning("æ— æ•°æ®")

    # ================= TAB 2: è¶‹åŠ¿å¯¹æ¯” =================
    with tab2:
        st.markdown("#### ğŸ†š å†å²è¶‹åŠ¿ & é£é™©æ´å¯Ÿ")
        
        cc1, cc2, cc3 = st.columns(3)
        all_depts_t = sorted(full_df['Dept'].unique().tolist())
        all_depts_t.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with cc1: t_dept = st.selectbox("åˆ†æéƒ¨é—¨", all_depts_t, key='t2_d')
        df_t1 = full_df if t_dept == "å…¨éƒ¨æ±‡æ€»" else full_df[full_df['Dept'] == t_dept]

        all_provs_t = sorted(df_t1['Provider'].unique().tolist())
        all_provs_t.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with cc2: t_prov = st.selectbox("åˆ†ææœåŠ¡å•†", all_provs_t, key='t2_p')
        df_t2 = df_t1 if t_prov == "å…¨éƒ¨æ±‡æ€»" else df_t1[df_t1['Provider'] == t_prov]

        all_whs_t = sorted(df_t2['Warehouse'].astype(str).unique().tolist())
        all_whs_t.insert(0, "å…¨éƒ¨æ±‡æ€»")
        with cc3: t_wh = st.selectbox("åˆ†æä»“åº“", all_whs_t, key='t2_w')
        t_final = df_t2 if t_wh == "å…¨éƒ¨æ±‡æ€»" else df_t2[df_t2['Warehouse'] == t_wh]
        
        available_dates = sorted(t_final['Date'].unique())
        selected_dates = st.multiselect("é€‰æ‹©åˆ†ææœˆä»½", available_dates, default=available_dates)
        
        if len(selected_dates) > 0:
            chart_df = t_final[t_final['Date'].isin(selected_dates)]
            
            st.divider()
            latest_month = sorted(selected_dates)[-1]
            latest_data = t_final[t_final['Date'] == latest_month]
            
            dead_fee = latest_data[latest_data['Age_Range'] == '360å¤©+']['Fee'].sum()
            total_fee = latest_data['Fee'].sum()
            total_qty = latest_data['Qty'].sum()
            cpu = total_fee / total_qty if total_qty > 0 else 0
            
            kp1, kp2, kp3 = st.columns(3)
            kp1.metric(f"{latest_month} æ€»ä»“ç§Ÿ", f"${total_fee:,.0f}")
            kp2.metric(f"ğŸ“‰ å•ä½ä»“ç§Ÿæˆæœ¬", f"${cpu:.3f} /ä»¶")
            kp3.metric(f"ğŸ’° 360å¤©+æ½œåœ¨èŠ‚çœ", f"${dead_fee:,.0f}")
            
            st.divider()
            # èšåˆ
            agg_df = chart_df.groupby(['Date', 'Age_Range'], observed=True).agg({
                'Qty': 'sum', 'Fee': 'sum', 'Vol': 'sum'
            }).reset_index()
            
            st.markdown("##### ğŸ“¦ å„åº“é¾„æ®µåº“å­˜é‡å¯¹æ¯”")
            base_chart = alt.Chart(agg_df).encode(
                x=alt.X('Age_Range', sort=AGE_LABELS, title="åº“é¾„åˆ†æ®µ"),
                y=alt.Y('Qty', title="åº“å­˜æ•°é‡"),
                color=alt.Color('Date', title="æœˆä»½"),
                tooltip=['Date', 'Age_Range', 'Qty']
            )
            grouped_bar = base_chart.mark_bar().encode(xOffset='Date').properties(height=350)
            st.altair_chart(grouped_bar, use_container_width=True)
            
            c_fee, c_cpu = st.columns(2)
            with c_fee:
                st.markdown("##### ğŸ’° è´¹ç”¨ç»“æ„")
                fee_pivot = agg_df.pivot(index='Date', columns='Age_Range', values='Fee')
                sorted_cols = [c for c in AGE_LABELS if c in fee_pivot.columns]
                st.bar_chart(fee_pivot[sorted_cols])
            
            with c_cpu:
                st.markdown("##### ğŸ“‰ å•ä½ä»“ç§Ÿæˆæœ¬è¶‹åŠ¿")
                cpu_trend = chart_df.groupby('Date', observed=True).apply(
                    lambda x: pd.Series({'CPU': x['Fee'].sum() / x['Qty'].sum() if x['Qty'].sum() > 0 else 0})
                ).reset_index()
                cpu_chart = alt.Chart(cpu_trend).mark_line(point=True).encode(
                    x='Date',
                    y=alt.Y('CPU', title='å•ä»¶æˆæœ¬ ($)'),
                    tooltip=['Date', alt.Tooltip('CPU', format='.3f')]
                ).properties(height=300)
                st.altair_chart(cpu_chart, use_container_width=True)

            st.divider()
            st.markdown("#### ğŸš¨ åº“å­˜æ¶åŒ–ç›‘æ§")
            if len(selected_dates) >= 2:
                sorted_dates = sorted(selected_dates)
                curr_month = sorted_dates[-1]
                prev_month = sorted_dates[-2]
                
                group_cols = ['SKU', 'Warehouse', 'Dept', 'Provider']
                cols_needed = group_cols + ['Age_Range', 'Fee']
                
                df_curr = chart_df[chart_df['Date'] == curr_month][cols_needed]
                df_prev = chart_df[chart_df['Date'] == prev_month][group_cols + ['Age_Range']]
                
                merged = pd.merge(df_prev, df_curr, on=group_cols, suffixes=('_old', '_new'))
                merged['idx_old'] = merged['Age_Range_old'].map(AGE_MAP).fillna(-1)
                merged['idx_new'] = merged['Age_Range_new'].map(AGE_MAP).fillna(-1)
                
                worsened = merged[merged['idx_new'] > merged['idx_old']].copy()
                
                if worsened.empty:
                    st.success("ğŸ‰ æ— åº“å­˜æ¶åŒ–ã€‚")
                else:
                    worsened['Fee'] = worsened['Fee'].astype(float)
                    top_worsened = worsened.sort_values('Fee', ascending=False).head(20)
                    st.dataframe(top_worsened[['SKU', 'Dept', 'Warehouse', 'Age_Range_old', 'Age_Range_new', 'Fee']].rename(columns={'Age_Range_old': f'{prev_month} åº“é¾„', 'Age_Range_new': f'{curr_month} åº“é¾„', 'Fee': 'å½“å‰ä»“ç§Ÿ($)'}).style.format({'å½“å‰ä»“ç§Ÿ($)': '${:.2f}'}).background_gradient(subset=['å½“å‰ä»“ç§Ÿ($)'], cmap='Reds'), use_container_width=True)
            else:
                st.info("ğŸ’¡ è¯·é€‰æ‹©è‡³å°‘ 2 ä¸ªæœˆä»½ä»¥å¯ç”¨æ¶åŒ–ç›‘æ§ã€‚")